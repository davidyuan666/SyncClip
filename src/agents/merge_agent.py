import os
from src.utils.video_clip_util import VideoClipUtil
from threading import Thread
import logging
from src.utils.tencent_cos_util import COSOperationsUtil
from src.utils.http_util import HttpUtil
from src.utils.gpu_util import GPUUtil
import ffmpeg
from tqdm import tqdm
import subprocess
import time  # ç¡®ä¿åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥
import uuid
from urllib.parse import urlparse

class MergeAgent:
    def __init__(self):
        self.cos_bucket_name = os.getenv('COS_BUCKET_NAME')
        self.cos_ops_util = COSOperationsUtil()
        self.video_clip_util = VideoClipUtil()
        self.http_util = HttpUtil()
        self.blip_video_captions_api_url = os.getenv('BLIP_VIDEO_CAPTIONS_API_URL')
        self.synthesize_video_api_url = os.getenv('SYNTHESIZE_VIDEO_API_URL')
        self.merge_dir = os.path.join(os.getcwd(), 'merge')
        self.base_cos_url = os.getenv('BASE_COS_URL')
        self.project_dir = os.path.join(os.getcwd(), 'temp')
        self.gpu_util = GPUUtil()
        self.logger = logging.getLogger(__name__)

    '''
    å…¥å£å‡½æ•°
    '''
    async def process_merge(self, data):
        try:
            # æ£€æŸ¥å¿…è¦çš„é”®æ˜¯å¦å­˜åœ¨
            required_keys = ['projectNo', 'preset', 'clips', 'callbackUrl']
            for key in required_keys:
                if key not in data:
                    raise ValueError(f"Missing required key: {key}")


            self.logger.info(f'================================> process merge data: {data}')

            project_no = data['projectNo']
            preset = data['preset']
            clips = data['clips']
            self.callback_url =  data['callbackUrl']
            narration = data['narration']
            self.logger.info('[step 1]:merge clips with transition effect')
            local_merged_video_path = self._merge_clips_with_transition_effect_by_ffmpeg(
                clips,
                project_no
            )

                        
            upload_response = self.upload_video_to_cos(local_merged_video_path, project_no)
            if upload_response is None:
                raise ValueError("Upload response is None")
            
            merged_video_url = upload_response.get('video_url', '')
            if not merged_video_url:
                raise ValueError("No video URL in upload response")
            
            self.logger.info(f'ğŸ‰ Merged video URL: ğŸ”— {merged_video_url} âœ…')
            
            
            self.logger.info('[step 2]:generate narration')
            
            # ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
            narration_audio_path = self.video_clip_util._generate_audio(narration, preset, project_no)
            # 3. ç”Ÿæˆå­—å¹•æ–‡ä»¶
            subtitle_path = self._generate_subtitles(narration_audio_path, narration)

            '''
            åå¤„ç†
            '''
            self.logger.info('[step 3]:apply effects')
            processed_video_path, video_duration = self.video_clip_util.apply_effects_with_transition_by_ffmpeg(
                local_merged_video_path, 
                subtitle_path,
                narration_audio_path,
                preset,
                project_no  # æ·»åŠ  project_no å‚æ•°
            )
            
            self.logger.info(f'processed video path: {processed_video_path}')
            self.logger.info(f'video duration: {video_duration}')
            '''
            ä¸Šä¼ 
            '''
            self.logger.info('[step 4]:upload merged video to cos')
            upload_response = self.upload_video_to_cos(processed_video_path, project_no)
            if upload_response is None:
                raise ValueError("Upload response is None")
            
            merged_video_url = upload_response.get('video_url', '')
            if not merged_video_url:
                raise ValueError("No video URL in upload response")

            # Prepare the callback data
            callback_data = {
                "data": {
                    "projectNo": project_no,
                    "videoUrl": merged_video_url,
                    "duration": int(video_duration)  # å‘ä¸‹å–æ•´
                }
            }

            Thread(target=self.http_util._send_callback, args=(self.callback_url, callback_data)).start()

            self.logger.info(f'====> callback data is:\n {callback_data}')

            return callback_data

        except Exception as e:
            self.logger.error(f'error is: {str(e)}')
            error_data = {
                "error": {
                    "code": 500,
                    "message": f"Internal server error during merge process: {str(e)}"
                }
            }
            
            if 'callback_url' in locals():
                Thread(target=self.http_util._send_callback, args=(self.callback_url, error_data)).start()

            return error_data
    
    def _generate_subtitles(self, narration_audio_path, narration_content):
        """ç”Ÿæˆ SRT æ ¼å¼å­—å¹•æ–‡ä»¶"""
        try:
            subtitle_path = os.path.join(self.project_dir, f"subtitle_{int(time.time())}.srt")
            
            # é¦–å…ˆå°è¯•ä½¿ç”¨ LLM è·å–éŸ³é¢‘åˆ†æ®µ
            try:
                audio_segments = self.video_clip_util._get_audio_segments(narration_audio_path)
                if audio_segments:
                    self.logger.info("Using LLM audio segments for subtitle generation")
                    return self._generate_subtitles_from_segments(subtitle_path, audio_segments)
            except Exception as e:
                self.logger.warning(f"LLM audio segmentation failed: {str(e)}, falling back to traditional method")
            
            # é™çº§ï¼šä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
            self.logger.info("Falling back to traditional subtitle generation method")
            return self._generate_subtitles_traditional(subtitle_path, narration_audio_path,narration_content)
            
        except Exception as e:
            self.logger.error(f"Error in subtitle generation: {str(e)}")
            raise
            

    def _format_time(self, seconds):
        """å°†ç§’æ•°è½¬æ¢ä¸º SRT æ—¶é—´æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        seconds = seconds % 60
        milliseconds = int((seconds - int(seconds)) * 1000)
        return f"{hours:02d}:{minutes:02d}:{int(seconds):02d},{milliseconds:03d}"
    

    def _get_audio_duration(self, audio_path):
        """ä½¿ç”¨ffmpegè·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿"""
        try:
            cmd = [
                'ffprobe', 
                '-v', 'error',
                '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                audio_path
            ]
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                raise Exception(f"FFprobe error: {result.stderr}")
                
            duration = float(result.stdout.strip())
            return duration
        except Exception as e:
            self.logger.error(f"Error getting audio duration: {str(e)}")
            raise


    def _generate_subtitles_from_segments(self, subtitle_path, audio_segments):
        """ä½¿ç”¨ LLM éŸ³é¢‘åˆ†æ®µç”Ÿæˆå­—å¹•"""
        try:
            with open(subtitle_path, 'w', encoding='utf-8') as f:
                for i, segment in enumerate(audio_segments, 1):
                    start_str = self._format_time(segment['start'])
                    end_str = self._format_time(segment['end'])
                    text = segment['text'].strip()
                    
                    # å†™å…¥ SRT æ ¼å¼
                    f.write(f"{i}\n")
                    f.write(f"{start_str} --> {end_str}\n")
                    f.write(f"{text}\n\n")
                    
            self.logger.info(f"Generated subtitles using LLM segments: {len(audio_segments)} segments")
            return subtitle_path
            
        except Exception as e:
            self.logger.error(f"Error in LLM subtitle generation: {str(e)}")
            raise
            
    def _generate_subtitles_traditional(self, subtitle_path, narration_audio_path,narration_content):
        """ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•ç”Ÿæˆå­—å¹•"""
        try:
            # å°†æ—ç™½å†…å®¹æŒ‰å¥å­åˆ†å‰²
            sentences = narration_content.split('ã€‚')
            sentences = [s.strip() for s in sentences if s.strip()]
            
            # ä¼°ç®—æ¯å¥è¯çš„æ—¶é—´æˆ³
            total_duration = self._get_audio_duration(narration_audio_path)
            avg_duration = total_duration / len(sentences)
            
            with open(subtitle_path, 'w', encoding='utf-8') as f:
                current_time = 0
                for i, sentence in enumerate(sentences, 1):
                    # æ ¹æ®å¥å­é•¿åº¦è°ƒæ•´æŒç»­æ—¶é—´
                    duration = min(avg_duration * (len(sentence) / 20), avg_duration * 1.5)  # 20ä¸ªå­—ä¸ºåŸºå‡†
                    
                    start_time = current_time
                    end_time = start_time + duration
                    
                    # è½¬æ¢æ—¶é—´æ ¼å¼
                    start_str = self._format_time(start_time)
                    end_str = self._format_time(end_time)
                    
                    # å†™å…¥ SRT æ ¼å¼
                    f.write(f"{i}\n")
                    f.write(f"{start_str} --> {end_str}\n")
                    f.write(f"{sentence}\n\n")
                    
                    current_time = end_time + 0.1  # æ·»åŠ å°é—´éš”
                    
            self.logger.info(f"Generated subtitles using traditional method: {len(sentences)} segments")
            return subtitle_path
            
        except Exception as e:
            self.logger.error(f"Error in traditional subtitle generation: {str(e)}")
            raise


    def upload_video_to_cos(self, local_video_path, project_no):
        """Upload merged video to COS
        
        Args:
            video_path (str): Local path to the video file
            project_no (str): Project identifier
            
        Returns:
            str: Public URL of the uploaded video
        """
        try:
            if not os.path.exists(local_video_path):
                raise FileNotFoundError(f"Local Video file not found: {local_video_path}")
            
            # Create the COS path with project number, UUID, and 'merged' folder
            filename = os.path.basename(local_video_path)
            remote_cos_path = f"{project_no}/merged/{str(uuid.uuid4())}_{filename}"
            
            self.logger.info(f"Starting upload of {local_video_path} to COS...")
            
            # Upload the video to COS
            self.cos_ops_util.upload_file(
                local_file_path=local_video_path,
                cos_file_path=remote_cos_path
            )
            
            video_url = self.cos_ops_util.get_file_url(remote_cos_path)

            self.logger.info(f"Successfully uploaded merged video to COS: {remote_cos_path}")
            
            return {
                "video_url": video_url,
                "project_no": project_no
            }
            
        except Exception as e:
            self.logger.error(f"Error uploading merged video {local_video_path} to COS: {str(e)}")
            return None


    def _merge_clips_with_transition_effect_by_ffmpeg(self, clips, project_no):
        """ä½¿ç”¨ ffmpeg-python åˆå¹¶è§†é¢‘å¹¶æ·»åŠ è½¬åœºæ•ˆæœ"""
        try:
            # å®šä¹‰è½¬åœºæ•ˆæœæ˜ å°„
            xfade_effects = {
                0: "fade",        # Angular -> fade
                1: "fadeblack",   # Bounce -> fadeblack
                2: "fadewhite",   # Burn -> fadewhite
                3: "distance",    # CrossWarp -> distance
                4: "wipeleft",    # Cube -> wipeleft
                5: "wiperight",   # Directional -> wiperight
                6: "fade",        # Fade -> fade
                7: "fadegrays",   # FadeGrayScale -> fadegrays
                8: "smoothleft",  # Morph -> smoothleft
                9: "circleclose", # Rotate -> circleclose
                10: "zoominx",    # SimpleZoom -> zoominx
                11: "squeezev",   # SquaresWire -> squeezev
                12: "circlecrop", # TangentialBlur -> circlecrop
                13: "wipetop"     # Wind -> wipetop
            }

            if not clips:
                raise ValueError("No clips provided")

            # åˆ›å»ºé¡¹ç›®ç›®å½•
            project_dir = os.path.join(self.merge_dir, project_no)
            os.makedirs(project_dir, exist_ok=True)
            self.logger.info(f"Working directory: {project_dir}")

            # å¤„ç†è§†é¢‘ç‰‡æ®µ
            video_paths = []
            transition_effects = []
            
            # 1. å¤„ç†æ‰€æœ‰è§†é¢‘å’Œè½¬åœºæ•ˆæœ
            for i, clip in enumerate(clips):
                if clip['type'] == 'video':
                    video_url = clip.get('videoUrl')
                    if not video_url:
                        self.logger.warning(f"Missing videoUrl in clip {i}")
                        continue

                    self.logger.info(f"Processing video {i+1}: {video_url}")
                    
                    local_path = self._download_video_from_cos(video_url, project_no)
                    if not local_path or not os.path.exists(local_path):
                        self.logger.error(f"Failed to download video from {video_url}")
                        continue

                    processed_filename = f"processed_{i}_{os.path.basename(local_path)}"
                    processed_path = os.path.join(project_dir, processed_filename)
                    
                    try:
                        # è·å– GPU ç¼–ç å‚æ•°
                        encoding_params = self.gpu_util.get_encoding_params()
                        self.logger.info(f"Using encoding params for video processing: {encoding_params}")
                        
                        stream = (
                            ffmpeg
                            .input(local_path)
                            .filter('scale', 1080, 1920, force_original_aspect_ratio='decrease')
                            .filter('pad', 1080, 1920, '(ow-iw)/2', '(oh-ih)/2')
                            .output(processed_path, **encoding_params)
                            .overwrite_output()
                        )
                        
                        self.logger.info(f"Processing video with ffmpeg-python using GPU: {processed_path}")
                        stream.run(capture_stderr=True)
                        
                        video_paths.append(processed_path)
                        self.logger.info(f"Successfully processed video to: {processed_path}")
                        
                        os.remove(local_path)  # æ¸…ç†åŸå§‹ä¸‹è½½æ–‡ä»¶
                        
                    except ffmpeg.Error as e:
                        self.logger.error(f"FFmpeg error: {e.stderr.decode() if e.stderr else 'No error output'}")
                        # å¦‚æœ GPU å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ° CPU å¤„ç†
                        self.logger.info("Falling back to CPU processing...")
                        stream = (
                            ffmpeg
                            .input(local_path)
                            .filter('scale', 1080, 1920, force_original_aspect_ratio='decrease')
                            .filter('pad', 1080, 1920, '(ow-iw)/2', '(oh-ih)/2')
                            .output(processed_path,
                                vcodec='libx264',
                                acodec='aac',
                                preset='medium',
                                pix_fmt='yuv420p',
                                crf=23)
                            .overwrite_output()
                        )
                        stream.run(capture_stderr=True)
                        continue
                        
                elif clip['type'] == 'effect':
                    effect = xfade_effects.get(clip.get('transitionEffect', 0), 'fade')
                    transition_effects.append(effect)
                    self.logger.info(f"Added transition effect: {effect}")

            # 2. æ£€æŸ¥å¤„ç†åçš„è§†é¢‘æ•°é‡
            if len(video_paths) < 2:
                if len(video_paths) == 1:
                    self.logger.info("Only one video processed, returning it directly")
                    return video_paths[0]
                raise ValueError(f"Not enough valid videos to merge (found {len(video_paths)})")

            try:
                # 3. åˆå¹¶è§†é¢‘å¹¶æ·»åŠ è½¬åœºæ•ˆæœ
                output_path = os.path.join(project_dir, f"{project_no}_final_{uuid.uuid4()}.mp4")
                current_input = video_paths[0]
                
                for i in range(1, len(video_paths)):
                    temp_output = f"{output_path}.temp{i}.mp4"
                    effect = transition_effects[i-1] if i-1 < len(transition_effects) else 'fade'
                    
                    try:
                        # è·å–ç¬¬ä¸€ä¸ªè§†é¢‘çš„æŒç»­æ—¶é—´
                        probe = ffmpeg.probe(current_input)
                        duration = float(probe['streams'][0]['duration'])
                        
                        self.logger.info(f"[ğŸ¬ ffmpeg] Applying transition âœ¨ {effect} âœ¨ between videos {i} and {i+1} ğŸ”„")
                        # ä½¿ç”¨ ffmpeg-python æ„å»ºè½¬åœºæ•ˆæœ
                        input1 = ffmpeg.input(current_input)
                        input2 = ffmpeg.input(video_paths[i])
                        
                        joined = ffmpeg.filter(
                            [input1, input2],
                            'xfade',
                            transition=effect,
                            duration=1,
                            offset=duration-1
                        )
                        
                       # ä½¿ç”¨ GPU å·¥å…·ç±»è·å–ç¼–ç å‚æ•°
                        output_options = self.gpu_util.get_encoding_params()
                        self.logger.info(f"Using encoding options: {output_options}")
                        
                        stream = ffmpeg.output(
                            joined,
                            temp_output,
                            **output_options
                        ).overwrite_output()
                        
                        stream.run(capture_stderr=True)
                        
                        if not os.path.exists(temp_output):
                            raise ValueError(f"Failed to create transition output: {temp_output}")
                        
                        current_input = temp_output
                        
                    except ffmpeg.Error as e:
                        self.logger.error(f"FFmpeg error during transition: {e.stderr.decode() if e.stderr else 'No error output'}")
                        # å¦‚æœè½¬åœºå¤±è´¥ï¼Œå°è¯•ç›´æ¥è¿æ¥
                        self.logger.info("Falling back to direct concatenation...")
                        
                        try:
                            stream = (
                                ffmpeg
                                .concat(
                                    ffmpeg.input(current_input),
                                    ffmpeg.input(video_paths[i])
                                )
                                .output(temp_output)
                                .overwrite_output()
                            )
                            stream.run(capture_stderr=True)
                            current_input = temp_output
                            
                        except ffmpeg.Error as concat_error:
                            self.logger.error(f"Concat error: {concat_error.stderr.decode() if concat_error.stderr else 'No error output'}")
                            raise

                # 4. é‡å‘½åæœ€åçš„è¾“å‡ºæ–‡ä»¶
                os.rename(current_input, output_path)
                self.logger.info(f"Successfully created merged video: {output_path}")
                return output_path

            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                for video_path in video_paths:
                    try:
                        if os.path.exists(video_path):
                            os.remove(video_path)
                    except Exception as e:
                        self.logger.warning(f"Failed to cleanup file {video_path}: {str(e)}")
                
                # æ¸…ç†ä¸´æ—¶è½¬åœºæ–‡ä»¶
                for i in range(1, len(video_paths)):
                    temp_file = f"{output_path}.temp{i}.mp4"
                    try:
                        if os.path.exists(temp_file):
                            os.remove(temp_file)
                    except Exception as e:
                        self.logger.warning(f"Failed to cleanup temp file {temp_file}: {str(e)}")

        except Exception as e:
            self.logger.error(f"Failed to merge clips with transitions: {str(e)}")
            return None
        

    
    def _download_video_from_cos(self, cos_video_url, project_no):
        try:
            print(f'cos video url: {cos_video_url}')

            # Extract remote path from URL
            if 'https' in cos_video_url:
                parsed_url = urlparse(cos_video_url)
                remote_path = parsed_url.path.lstrip('/')
                if remote_path.startswith(self.cos_ops_util.bucket_name):
                    remote_path = remote_path[len(self.cos_ops_util.bucket_name):].lstrip('/')
            else:
                remote_path = cos_video_url

            # Generate a shorter filename using UUID
            file_extension = os.path.splitext(remote_path)[1]  # Get original extension
            short_filename = f"{uuid.uuid4().hex[:8]}{file_extension}"  # Use first 8 chars of UUID
            
            # Create temp directory path
            temp_dir = os.path.join(os.getcwd(), 'temp', project_no)
            video_local_path = os.path.join(temp_dir, short_filename)

            # Ensure the directory exists
            os.makedirs(temp_dir, exist_ok=True)

            # Download the file
            print(f"\033[93mDownloading {remote_path}\033[0m")
            try:
                self.cos_ops_util.download_file(
                    remote_path,
                    video_local_path
                )
            except Exception as e:
                print(f"Failed to download from COS: {str(e)}")
                raise
                
            if not os.path.exists(video_local_path):
                raise FileNotFoundError(f"File download failed - file not found at {video_local_path}")
            
            if os.path.getsize(video_local_path) == 0:
                raise ValueError(f"Downloaded file is empty: {video_local_path}")

            print(f"Successfully downloaded video to {video_local_path}")
            return video_local_path
                
        except Exception as e:
            print(f"\033[93mError downloading video from {cos_video_url}: {str(e)}\033[0m")
            return None
        
        